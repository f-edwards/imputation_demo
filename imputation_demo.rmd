---
title: "imputation_demo.rmd"
output: powerpoint_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = F)
```

# Approaches to missing data 101

## Why should we care?

* Most statistical software will conduct "complete-case analysis" by default
* Depending on how much data is missing in the variables you've chosen, this may result in throwing away a lot of perfectly good information!
* This (at minimum) biases your standard errors, and may bias your coefficient estimates
* With a few assumptions, we can correct the problem

## Why are data missing?

* **Missing completely at random (MCAR)**: The probability of a value being missing is the same for all observations in the data
* **Missing at random (MAR)**: The probability of a value being missing is random, conditional on other observed variables
* **Non-random missing data (MNAR)**: The probability of a value being missing depends on either *A)* some unobserved variable or *B)* the value itself (censorship)

## Basic approaches to missing data

* Listwise deletion (complete case analysis)
     + Appropriate for data with very few missing observations, or when missingness is completely at random and missingness is rare (independent of all observed and unobservable variables)
* Using alternative information (e.g. borrowing observation of sex from prior survey wave)
* Nonresponse weighting
     + Becomes difficult when many variables are missing, sub-populations of interest differ

## Basic approaches to missing data

* Deterministic imputation methods
     + Many examples: linear interpolation or last observed, regression imputation
     + This is generally a bad idea. Covariance estimates and standard errors are biased downward

## Basic approaches to missing data

* Multiple imputation
     + Iterative modeling of all missing outcomes/predictors in model
     + Produces multiple possible random datasets, allows you to average over uncertainty generated by missing data
     + Does not recover "true" values
     + Under missing at random assumption, generates unbiased parameter and variance estimates
     
## My preferred approach

* Understand your data!
     + Read the documentation
     + Do plenty of exploratory data analysis (cross tabs, data visuals, descriptives, look at the raw data)
     + Develop an understanding of the mechanisms of missing data in each dataset you use
     + Test your ideas for mechanisms of missing data when feasible
     
## My preferred approach

* If MAR is a reasonable assumption (it often is), conduct multiple imputation
     + Because MAR is conditional on observables, including many variables in imputation models is often a good idea
* Apply preferred final model / analysis over each imputed dataset, combine with Rubin's rules, report revised estimates. 

# Applying missing data methods to AFCARS/NCANDS: a brief introduction

## Some notes before starting

* More work will be required to get it right for your analysis
* I'm using R (and the mice package) for my demo, but all major statistical packages (Stata, SAS, SPSS) use similar techniques
* All code (and slides, but no data!) is available at https://github.com/f-edwards/nytd_missing_data_demo
* We are using NYTD Outcomes File, Cohort Age 17 in FY2011, Waves 1-3 (NDACAN Dataset 202). 
* Submit data requests at https://www.ndacan.cornell.edu/datasets/request-dataset.cfm
